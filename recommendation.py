"""
recommendation.py â€” Há»‡ thá»‘ng tra cá»©u (Retrieval) tÃ¬m Q&A liÃªn quan nháº¥t.
Káº¿t há»£p TF-IDF cosine similarity + Sentence Embedding cosine similarity.

=== FIXES ===
1. [NotFittedError] ThÃªm _validate_tfidf() kiá»ƒm tra idf_ attribute sau khi load.
   Náº¿u vectorizer chÆ°a fitted â†’ tá»± gá»i rebuild TF-IDF tá»« DataFrame.
2. [Robustness] Náº¿u rebuild cÅ©ng tháº¥t báº¡i â†’ set vectorizer = None,
   _tfidf_scores() tráº£ vá» zeros â†’ há»‡ thá»‘ng fallback sang embedding-only.
3. [Logging] In rÃµ tráº¡ng thÃ¡i: loaded OK / rebuild / disabled.
"""
import warnings, os
import numpy as np
import joblib
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.utils.validation import check_is_fitted
from sklearn.exceptions import NotFittedError

warnings.filterwarnings("ignore")

from config import (
    TFIDF_MATRIX_PATH, TFIDF_VECTORIZER_PATH,
    EMBEDDING_CACHE_PATH, EMBEDDING_MODEL
)


class RetrievalEngine:
    """
    Chá»©a toÃ n bá»™ logic tra cá»©u.
    Khá»Ÿi táº¡o 1 láº§n, reuse trong suá»‘t session Streamlit.
    """

    def __init__(self, df):
        self.df = df
        self.tfidf_vectorizer = None
        self.tfidf_matrix     = None
        self.embeddings       = None
        self.embed_model      = None
        self._load_artifacts()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Load pre-built artifacts
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _load_artifacts(self):
        self._load_tfidf()
        self._load_embeddings()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Load + Validate TF-IDF
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _load_tfidf(self):
        """
        Load TF-IDF vectorizer + matrix tá»« .pkl.
        Sau khi load, validate báº±ng check_is_fitted().
        Náº¿u chÆ°a fitted hoáº·c file khÃ´ng tá»“n táº¡i â†’ auto-rebuild tá»« self.df.
        """
        loaded_vectorizer = None
        loaded_matrix     = None

        # â”€â”€ Step 1: Thá»­ load tá»« file â”€â”€
        if os.path.exists(TFIDF_VECTORIZER_PATH) and os.path.exists(TFIDF_MATRIX_PATH):
            try:
                loaded_vectorizer = joblib.load(TFIDF_VECTORIZER_PATH)
                loaded_matrix     = joblib.load(TFIDF_MATRIX_PATH)
                print("[RETRIEVAL] TF-IDF .pkl files loaded from disk.")
            except Exception as e:
                print(f"[RETRIEVAL] âš ï¸ Lá»—i load TF-IDF .pkl: {e}")
                loaded_vectorizer = None
                loaded_matrix     = None
        else:
            print("[RETRIEVAL] âš ï¸ TF-IDF .pkl files khÃ´ng tÃ¬m tháº¥y.")

        # â”€â”€ Step 2: Validate fitted â”€â”€
        if loaded_vectorizer is not None:
            if self._validate_tfidf(loaded_vectorizer):
                # âœ… Vectorizer há»£p lá»‡ + Ä‘Ã£ fitted
                self.tfidf_vectorizer = loaded_vectorizer
                self.tfidf_matrix     = loaded_matrix
                print("[RETRIEVAL] âœ… TF-IDF vectorizer validated â€” fitted OK.")
                return
            else:
                # âŒ Vectorizer load Ä‘Æ°á»£c nhÆ°ng chÆ°a fitted â†’ rebuild
                print("[RETRIEVAL] âš ï¸ TF-IDF vectorizer chÆ°a fitted. Äang rebuild...")

        # â”€â”€ Step 3: Rebuild náº¿u cáº§n â”€â”€
        self._rebuild_tfidf()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Validate: check idf_ attribute
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    @staticmethod
    def _validate_tfidf(vectorizer) -> bool:
        """
        Kiá»ƒm tra vectorizer Ä‘Ã£ Ä‘Æ°á»£c fit chÆ°a.
        TfidfVectorizer sau fit sáº½ cÃ³ attribute 'idf_'.
        """
        try:
            check_is_fitted(vectorizer, attributes=["idf_"])
            return True
        except NotFittedError:
            return False

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Rebuild TF-IDF tá»« DataFrame
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _rebuild_tfidf(self):
        """
        Rebuild TF-IDF vectorizer + matrix tá»« self.df.
        Dump láº¡i .pkl Ä‘á»ƒ reuse cho láº§n cháº¡y sau.
        """
        if self.df is None or "Combined" not in self.df.columns:
            print("[RETRIEVAL] âŒ KhÃ´ng thá»ƒ rebuild TF-IDF: DataFrame thiáº¿u cá»™t 'Combined'.")
            print("[RETRIEVAL] âš ï¸ TF-IDF disabled â€” há»‡ thá»‘ng sáº½ chá»‰ dÃ¹ng Sentence Embeddings.")
            self.tfidf_vectorizer = None
            self.tfidf_matrix     = None
            return

        try:
            from sklearn.feature_extraction.text import TfidfVectorizer

            print("[RETRIEVAL] ðŸ”¨ Äang rebuild TF-IDF vectorizer tá»« DataFrame...")
            vectorizer  = TfidfVectorizer(max_features=20000, ngram_range=(1, 2), sublinear_tf=True)
            tfidf_matrix = vectorizer.fit_transform(self.df["Combined"].tolist())

            # Validate láº¡i sau fit
            if not self._validate_tfidf(vectorizer):
                raise RuntimeError("Vectorizer váº«n chÆ°a fitted sau fit_transform().")

            # â”€â”€ Save artifacts â”€â”€
            os.makedirs(os.path.dirname(TFIDF_VECTORIZER_PATH), exist_ok=True)
            joblib.dump(vectorizer,  TFIDF_VECTORIZER_PATH)
            joblib.dump(tfidf_matrix, TFIDF_MATRIX_PATH)

            self.tfidf_vectorizer = vectorizer
            self.tfidf_matrix     = tfidf_matrix
            print(f"[RETRIEVAL] âœ… TF-IDF rebuild hoÃ n thÃ nh: {tfidf_matrix.shape} â†’ artifacts/")

        except Exception as e:
            print(f"[RETRIEVAL] âŒ Rebuild TF-IDF tháº¥t báº¡i: {e}")
            print("[RETRIEVAL] âš ï¸ TF-IDF disabled â€” há»‡ thá»‘ng sáº½ chá»‰ dÃ¹ng Sentence Embeddings.")
            self.tfidf_vectorizer = None
            self.tfidf_matrix     = None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Load Sentence Embeddings
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _load_embeddings(self):
        if os.path.exists(EMBEDDING_CACHE_PATH):
            try:
                self.embeddings = joblib.load(EMBEDDING_CACHE_PATH)
                from sentence_transformers import SentenceTransformer
                self.embed_model = SentenceTransformer(EMBEDDING_MODEL)
                print("[RETRIEVAL] âœ… Embedding cache loaded.")
            except Exception as e:
                print(f"[RETRIEVAL] âš ï¸ Lá»—i load Embeddings: {e}")
                self.embeddings  = None
                self.embed_model = None
        else:
            print("[RETRIEVAL] âš ï¸ Embedding cache not found. Run data_processing.py first.")
            self.embeddings  = None
            self.embed_model = None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # TF-IDF Similarity
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _tfidf_scores(self, query: str) -> np.ndarray:
        """
        TÃ­nh TF-IDF cosine similarity.
        Náº¿u vectorizer None (chÆ°a fitted / disabled) â†’ tráº£ vá» zeros.
        """
        if self.tfidf_vectorizer is None or self.tfidf_matrix is None:
            return np.zeros(len(self.df))

        # Double-check fitted trÆ°á»›c khi transform (safety net)
        if not self._validate_tfidf(self.tfidf_vectorizer):
            print("[RETRIEVAL] âš ï¸ TF-IDF vectorizer máº¥t fitted state. Thá»­ rebuild...")
            self._rebuild_tfidf()
            if self.tfidf_vectorizer is None:
                return np.zeros(len(self.df))

        try:
            q_vec  = self.tfidf_vectorizer.transform([query])
            scores = cosine_similarity(q_vec, self.tfidf_matrix).flatten()
            return scores
        except NotFittedError:
            print("[RETRIEVAL] âš ï¸ NotFittedError táº¡i transform â€” fallback zeros.")
            return np.zeros(len(self.df))

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Sentence Embedding Similarity
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _embed_scores(self, query: str) -> np.ndarray:
        if self.embed_model is None or self.embeddings is None:
            return np.zeros(len(self.df))
        q_emb  = self.embed_model.encode([query])
        scores = cosine_similarity(q_emb, self.embeddings).flatten()
        return scores

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Combined retrieval (weighted ensemble)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def retrieve(self, query: str, top_k: int = 3, alpha: float = 0.45) -> list[dict]:
        """
        Tráº£ vá» top_k káº¿t quáº£ liÃªn quan nháº¥t.
        alpha: weight cho TF-IDF (1-alpha cho embedding).

        Adaptive alpha:
        - Náº¿u TF-IDF disabled (vectorizer = None) â†’ alpha = 0 (chá»‰ dÃ¹ng embedding).
        - Náº¿u Embedding disabled â†’ alpha = 1 (chá»‰ dÃ¹ng TF-IDF).
        - Náº¿u cáº£ hai disabled â†’ tráº£ vá» top_k rows Ä‘áº§u tiÃªn (fallback).
        """
        tfidf_s  = self._tfidf_scores(query)
        embed_s  = self._embed_scores(query)

        # â”€â”€ Adaptive: náº¿u má»™t trong hai bá»‹ disabled â”€â”€
        tfidf_active  = self.tfidf_vectorizer is not None and np.any(tfidf_s != 0)
        embed_active  = self.embed_model is not None and np.any(embed_s != 0)

        if not tfidf_active and not embed_active:
            # â”€â”€ Cáº£ hai disabled â†’ fallback: tráº£ vá» top_k rows Ä‘áº§u â”€â”€
            print("[RETRIEVAL] âš ï¸ Cáº£ TF-IDF vÃ  Embedding Ä‘á»u inactive. Fallback top rows.")
            results = []
            for i in range(min(top_k, len(self.df))):
                row = self.df.iloc[i]
                results.append({
                    "Plant":         row.get("Plant", "Unknown"),
                    "Disease":       row.get("Disease", "Unknown"),
                    "Question":      row["Question"],
                    "Answer":        row["Answer"],
                    "question_type": row.get("question_type", "General"),
                    "image_path":    row.get("image_path", ""),
                    "score":         0.0
                })
            return results

        if not tfidf_active:
            effective_alpha = 0.0   # chá»‰ embedding
        elif not embed_active:
            effective_alpha = 1.0   # chá»‰ TF-IDF
        else:
            effective_alpha = alpha # default ensemble

        # Normalize to [0,1]
        def norm(arr):
            mn, mx = arr.min(), arr.max()
            return (arr - mn) / (mx - mn + 1e-9)

        combined = effective_alpha * norm(tfidf_s) + (1 - effective_alpha) * norm(embed_s)
        top_idx  = np.argsort(combined)[-top_k:][::-1]

        results = []
        for i in top_idx:
            row = self.df.iloc[i]
            results.append({
                "Plant":         row.get("Plant", "Unknown"),
                "Disease":       row.get("Disease", "Unknown"),
                "Question":      row["Question"],
                "Answer":        row["Answer"],
                "question_type": row.get("question_type", "General"),
                "image_path":    row.get("image_path", ""),
                "score":         float(combined[i])
            })
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Filter by plant / disease name
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def retrieve_by_disease(self, disease_name: str, top_k: int = 3) -> list[dict]:
        """TÃ¬m cÃ¡c Q&A cÃ³ Disease chá»©a disease_name (case-insensitive)."""
        if "Disease" not in self.df.columns:
            return []
        mask = self.df["Disease"].astype(str).str.lower().str.contains(
            disease_name.lower(), na=False
        )
        subset = self.df[mask]
        if subset.empty:
            return []

        results = []
        for _, row in subset.head(top_k).iterrows():
            results.append({
                "Plant":         row.get("Plant", "Unknown"),
                "Disease":       row.get("Disease", "Unknown"),
                "Question":      row["Question"],
                "Answer":        row["Answer"],
                "question_type": row.get("question_type", "General"),
                "image_path":    row.get("image_path", ""),
                "score":         1.0
            })
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Filter by question_type (9 PlantVillageVQA categories)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def retrieve_by_question_type(self, qtype: str, plant: str = "", top_k: int = 5) -> list[dict]:
        """
        TÃ¬m Q&A theo question_type.
        CÃ¡c loáº¡i há»i cá»§a PlantVillageVQA:
            - Existence & Sanity Check
            - Plant Species Identification
            - General Health Assessment
            - Visual Attribute Grounding
            - Detailed Verification
            - Specific Disease Identification
            - Comprehensive Description
            - Causal Reasoning
            - Counterfactual Reasoning
        """
        if "question_type" not in self.df.columns:
            return []

        mask = self.df["question_type"].astype(str).str.lower().str.contains(
            qtype.lower(), na=False
        )
        if plant:
            mask = mask & self.df["Plant"].astype(str).str.lower().str.contains(
                plant.lower(), na=False
            )

        subset = self.df[mask]
        if subset.empty:
            return []

        results = []
        for _, row in subset.head(top_k).iterrows():
            results.append({
                "Plant":         row.get("Plant", "Unknown"),
                "Disease":       row.get("Disease", "Unknown"),
                "Question":      row["Question"],
                "Answer":        row["Answer"],
                "question_type": row.get("question_type", "General"),
                "image_path":    row.get("image_path", ""),
                "score":         1.0
            })
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Get unique plants / diseases / question_types
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def get_plants(self) -> list[str]:
        if "Plant" not in self.df.columns:
            return []
        return sorted(self.df["Plant"].astype(str).unique().tolist())

    def get_diseases(self) -> list[str]:
        if "Disease" not in self.df.columns:
            return []
        return sorted(self.df["Disease"].astype(str).unique().tolist())

    def get_question_types(self) -> list[str]:
        if "question_type" not in self.df.columns:
            return []
        return sorted(self.df["question_type"].astype(str).unique().tolist())